import requests
from bs4 import BeautifulSoup
import pandas as pd

# Function to scrape the data from a single page
def scrape_page(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')

    tool_list = []

    for tool_box in soup.find_all('div', class_='tool_box'):
        tool_data = {}
        tool_data['Tool Name'] = tool_box.find('h5').text.strip()
        tool_data['Tool URL'] = tool_box.find('a', href=True)['href']
        tool_data['What is'] = tool_box.find('p', class_='font-weight-lighter').text.strip()
        tool_data['Pricing'] = tool_box.find('span', class_='pricing-badge').text.strip()
        tool_data['Tag'] = ', '.join([tag.text for tag in tool_box.find_all('span', class_='badge')])
        tool_list.append(tool_data)

    return tool_list

# Function to scrape all pages and combine the data
def scrape_all_pages(base_url, total_pages):
    all_tools = []
    for page in range(1, total_pages + 1):
        url = f'{base_url}?page={page}'
        tools_on_page = scrape_page(url)
        all_tools.extend(tools_on_page)
    return all_tools

# URL of the webpage to scrape
base_url = 'https://topai.tools/browse'
response = requests.get(base_url)
soup = BeautifulSoup(response.content, 'html.parser')
total_pages = int(soup.find('input', {'name': 'total_page'})['value'])

# Scrape all pages
data = scrape_all_pages(base_url, total_pages)

# Convert the data into a Pandas DataFrame
df = pd.DataFrame(data)

# Save the data to an Excel file
output_file = 'top_ai_tools.xlsx'
df.to_excel(output_file, index=False)

print(f"Data scraped and saved to '{output_file}'")
